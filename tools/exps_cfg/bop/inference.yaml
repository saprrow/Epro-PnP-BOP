pytorch:
  exp_id: 'epropnp_v2_no_model'
  task: 'rot' # 'rot | trans | rot_trans'
  cfg: ''           # path to configure file
  gpu: 0
  threads_num: 12
  debug: False
  save_mode: 'all'  # 'all' | 'best', save all models or only save the best model
  load_model: '../checkpoints/model_160.checkpoint'
  #load_model: '/home/zjw/projects/pose_estimation/EPro-PnP/EPro-PnP-6DoF/exp/epropnp_9_9/2023-09-09T20:41:24.755171/model_110.checkpoint' 
  test: False
  demo: False
  im_shape: [640, 480]

dataset:
  path: "../dataset/epro_3k/bop_data"
  name: 'lm'     # 'lm' | 'lmo'
  classes: ["centrum", "carton"]    # 'all' represents train on all classes, or you can list specific classes for training
  img_type: 'real_imgn'    # 'real' | 'imgn' | 'real_imgn'
  syn_num: 1000
  syn_samp_type: 'uniform' # 'uniform' | 'random'
  #[idx:[x_min, y_min, z_min]] unit:mm
  model_info: [[0.03445, 0.0344, 0.0625], [0.0835, 0.0780, 0.0600]]

dataiter:
  inp_res: 256
  out_res: 64
  dzi: True
  denoise_coor: True

augment:
  change_bg_ratio: 0.5
  pad_ratio: 1.5
  scale_ratio: 0.25
  shift_ratio: 0.25

network:
  # ------ backbone -------- #
  arch: 'resnet' # 'hg' | 'hg_refiner' | 'resnet' | 'resnet_refiner'
  back_freeze: False
  back_input_channel: 3 # # channels of backbone's input
  # hourglass backbone
  nFeats: 256 # # features in the hourglass'
  nStack: 4   # # hourglasses to stack
  nModules: 2 # # residual modules at each hourglass
  # resnet backbone
  numBackLayers: 34 # 18 | 34 | 50 | 101 | 152
  back_filters: 256 # number of filters for each layer
  # ------ rotation head -------- #
  rot_head_freeze: False
  rot_layers_num: 3
  rot_filters_num: 256 # number of filters for each layer
  rot_conv_kernel_size: 3 # kernel size for hidden layers
  rot_output_conv_kernel_size: 1 # kernel size for output layer
  rot_output_channels: 5 # # channels of output
  # ------ translation head -------- #
  trans_head_freeze: True
  trans_layers_num: 3
  trans_filters_num: 256
  trans_conv_kernel_size: 3
  trans_output_channels: 3

train:
  begin_epoch: 0
  end_epoch: 160
  test_interval: 10
  train_batch_size: 32
  lr_backbone: 1e-4
  lr_rot_head: 1e-4
  lr_trans_head: 1e-4
  lr_epoch_step:
  - 50
  - 100
  - 150
  lr_factor: 0.1
  optimizer_name: 'RMSProp'
  warmup_lr: 1e-5
  warmup_step: 500
  momentum: 0.0
  weightDecay: 0.0
  alpha: 0.99
  epsilon: 1e-8

loss:
  # coordinate regression loss
  rot_loss_type: 'L1'
  rot_loss_weight: 1.0
  # Monte Carlo loss
  mc_loss_weight: 0.2  # this value is small because the actual scale of the loss is large
  # derivative regularization loss
  t_loss_weight: 1.0
  r_loss_weight: 1.0

test:
  test_mode: 'all_fast' # 'pose' | 'add' | 'proj' | 'all' | 'pose_fast' | 'add_fast' | 'proj_fast' | 'all_fast'
                    # 'pose' means "#cm, #degrees", 'all' means evaluate on all metrics,
                    # 'fast' means the test batch size equals training batch size, otherwise 1
  cache_file: ''
  ignore_cache_file: True
  detection: 'FasterRCNN'
  disp_interval: 50
  vis_demo: False

